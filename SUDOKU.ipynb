{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SUDOKU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z79ziiWsEzI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OXFjbpH_l3N",
        "colab_type": "code",
        "outputId": "5935d990-d9dd-4784-9ede-ecdc5e5427aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import BatchNormalization, Conv2D, Reshape, Flatten, Activation, Dense\n",
        "from keras.models import Sequential\n",
        "from sudoku_data import getSudokuData, normalize, denormalize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHDjcZQX_1rF",
        "colab_type": "code",
        "outputId": "c4c41245-1335-4ee2-fdde-cf9e6ea8c74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d bryanpark/sudoku"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sudoku.zip to /content\n",
            "\r  0% 0.00/68.1M [00:00<?, ?B/s]\r  7% 5.00M/68.1M [00:00<00:02, 28.0MB/s]\r 15% 10.0M/68.1M [00:00<00:01, 32.5MB/s]\r 48% 33.0M/68.1M [00:00<00:00, 41.8MB/s]\r 91% 62.0M/68.1M [00:00<00:00, 56.3MB/s]\n",
            "\r100% 68.1M/68.1M [00:00<00:00, 87.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZAFprrtKLEL",
        "colab_type": "text"
      },
      "source": [
        "Obtenemos el conjunto de datos desde Kaggle, luego los preprocesamos en el archivo adjunto para obtener nuestros pares de conjuntos para las pruebas y el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoBJxITrdCu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train),(X_test,y_test) = getSudokuData('sudoku.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3-2mr9CKjXT",
        "colab_type": "text"
      },
      "source": [
        "Al igual que en la identificación de números, se usará una red neural convolucional de 3 capas de convolución donde la primera tiene la dimensión de un tablero de SUDOKU 9x9x1 y entre capa y capa, se normalizan las salidas para evitar los números exageradamente grandes. \n",
        "\n",
        "Finalmente se aplanan para ir a la etapa de clasificación donde la habrá 9x9x9 neuronas, las cuales representan las 81 casillas y las 9 posibilidades para cada casilla.\n",
        "\n",
        "Una vez teniendo las 729 probabilidades se agrupan a cada una de las probabilidades a una casilla,quedando como resultado un tensor de 81x9 donde se aplicará softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJRiyiedYUZ",
        "colab_type": "code",
        "outputId": "a44a9105-593d-487b-f4b7-2204a9cc120e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(81*9))\n",
        "model.add(Reshape((81, 9)))\n",
        "model.add(Activation('softmax')) \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.adam(lr=.001))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSGodcpDemMJ",
        "colab_type": "code",
        "outputId": "2c7247ef-8c55-4a61-e614-947fee4f7108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 800000 samples, validate on 200000 samples\n",
            "Epoch 1/2\n",
            "800000/800000 [==============================] - 225s 281us/step - loss: 0.4913 - val_loss: 0.3726\n",
            "Epoch 2/2\n",
            "800000/800000 [==============================] - 217s 272us/step - loss: 0.3570 - val_loss: 0.3514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d5413a7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a4Rya_GO9Q",
        "colab_type": "code",
        "outputId": "4ed38c8e-0d67-4026-f10d-ea6b0d2b5c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(np.argmax(model.predict(X_test[0].reshape(1,9,9,1)).squeeze(), axis=1).reshape((9,9))+1)\n",
        "print(model.predict(X_test[0].reshape(1,9,9,1)).shape)\n",
        "print(y_test[0].reshape(9,9)+1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7 1 2 3 9 5 4 8 6]\n",
            " [6 3 5 1 4 2 4 9 7]\n",
            " [9 8 4 3 3 6 5 9 2]\n",
            " [5 2 6 9 7 1 5 4 8]\n",
            " [8 4 3 5 6 2 1 7 9]\n",
            " [1 7 9 3 4 8 6 2 5]\n",
            " [3 6 8 2 5 9 7 5 4]\n",
            " [2 5 7 4 1 7 9 6 3]\n",
            " [4 9 7 6 5 3 2 5 1]]\n",
            "(1, 81, 9)\n",
            "[[7 1 2 8 9 5 4 3 6]\n",
            " [6 3 5 1 2 4 8 9 7]\n",
            " [9 8 4 7 3 6 5 1 2]\n",
            " [5 2 6 9 7 1 3 4 8]\n",
            " [8 4 3 5 6 2 1 7 9]\n",
            " [1 7 9 3 4 8 6 2 5]\n",
            " [3 6 8 2 1 9 7 5 4]\n",
            " [2 5 1 4 8 7 9 6 3]\n",
            " [4 9 7 6 5 3 2 8 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_9h6RPcNEKA",
        "colab_type": "text"
      },
      "source": [
        "Como se quiere recibir un sudoku, solo se debe predecir un juego, por lo que se envía un juego de dimensión 9x9x1 que hay que redimensionar a 1x9x9x1 ya que predict funciona con varias muestras.\n",
        "\n",
        "El resultado predicho tiene dimensión 1x81x9 por lo que usamos squeeze para quitar la dimensión 1 y dejarlo en 81x9.\n",
        "\n",
        "Luego se aplica np.argmax para obtener el índice con mayor probabilidad entre las 9 posibilidades que tiene cada casilla, obteniendo un tensor de dimensión 81 que llamamos ax que lo redimensionamos a un tablero 9x9 pred y como las neuronas de salida representan los números posibles le sumamos 1.\n",
        "\n",
        "Adicionalmente vamos a obtener un tensor con las probabilidades de cada uno de los valores de pred, para ello se busca la máxima probabilidad entre las 9 posibles para cada una de las 81 casillas con np.max y lo redimensionamos a un tablero de 9x9 que llamamos prob, cuyas probabilidades las redondeamos a 2 decimales.\n",
        "\n",
        "Como los resultados están normalizados debido al preprocesado ideal para el entrenamiento y predicción, se desnormalizan para tener el resultado real del tablero. Hasta aquí serviría para obtener un juego con IA, pero lo ideal sería que llenara cuadro a cuadro para así aumentar sus probabilidades de no fallar.\n",
        "\n",
        "En mask se van a evaluar las jugadas faltantes en el tablero del SUDOKU, se guarda 1 en la casilla donde falta colocar un número y 0 en donde ya está colocado.\n",
        "\n",
        "Si la suma de casillas vacías es 0, termina el ciclo, de lo contrario va a multiplicar la matriz de probabilidades por la máscara, siendo 0 en las casillas donde ya hay colocado un número y siendo la probabilidad de prob en las casillas donde hay que poner un número.\n",
        "\n",
        "Con np.argmax se ubica de entre las 81 casillas, la que tiene las mayor probabilidad (recordemos que las que ya están marcadas quedaron en 0 en el paso anterior), como argmax devuelve un índice, se utiliza unravel_index que devuelve la posición i,j de la casilla.\n",
        "\n",
        "Ya con la posición i,j se toma el valor de pred, y se introduce en el sudoku.\n",
        "\n",
        "Finalmente se noramaliza de nuevo el sudoku para repetir el proceso hasta que no queden casillas vacías."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18_yenu7QRGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resolveSudoku(sudoku):\n",
        "  sudoku = sudoku.reshape((9,9))\n",
        "  while(1):\n",
        "    out = model.predict(sudoku.reshape((1,9,9,1)))\n",
        "    out = out.squeeze()\n",
        "    ax = np.argmax(out, axis=1)\n",
        "    pred = ax.reshape((9,9))+1 \n",
        "    ax = np.max(out, axis=1)\n",
        "    prob = np.around(ax.reshape((9,9)), 2) \n",
        "    sudoku = denormalize(sudoku)\n",
        "\n",
        "    mask = (sudoku==0)\n",
        "\n",
        "    if(mask.sum()==0):\n",
        "        break\n",
        "        \n",
        "    real_prob = prob*mask\n",
        "\n",
        "    index = np.argmax(real_prob)\n",
        "\n",
        "    i, j = np.unravel_index(index, pred.shape)\n",
        "    sudoku[i][j] = pred[i][j]\n",
        "    sudoku = normalize(sudoku)\n",
        "  \n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdK5fvK9gxBU",
        "colab_type": "text"
      },
      "source": [
        "A continuación se procede a realizar 1000 juegos de validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPqUz7oJYECn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8429389b-7889-4733-d6dc-1382e7f7aec7"
      },
      "source": [
        "samples = 1000\n",
        "mistakes = 0\n",
        "for i in range(samples):\n",
        "  mistakes += not np.array_equal(resolveSudoku(X_test[i]),(y_test[i].reshape(9,9)+1))\n",
        "\n",
        "print(\"Ejemplos: \", samples, \"\\nErrores: \", mistakes, \"\\nPorcentaje de acierto: \", (samples-mistakes)/samples)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ejemplos:  1000 \n",
            "Errores:  35 \n",
            "Porcentaje de acierto:  0.965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_QdBS_8g5a2",
        "colab_type": "text"
      },
      "source": [
        "Un caso de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "336ZR06ZScdX",
        "colab_type": "code",
        "outputId": "fd0be69f-2f2b-4dbd-fe5c-ce27016ab2f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(denormalize(X_test[0]).reshape(9,9))\n",
        "print(resolveSudoku(X_test[0]))\n",
        "print(y_test[0].reshape(9,9)+1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 2. 0. 9. 5. 0. 0. 0.]\n",
            " [6. 3. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 8. 4. 0. 0. 6. 0. 0. 2.]\n",
            " [0. 0. 0. 0. 7. 0. 0. 4. 8.]\n",
            " [0. 4. 0. 5. 0. 0. 1. 7. 0.]\n",
            " [1. 0. 9. 0. 0. 8. 6. 2. 0.]\n",
            " [3. 0. 8. 0. 0. 9. 7. 0. 0.]\n",
            " [2. 5. 0. 4. 0. 0. 9. 6. 0.]\n",
            " [0. 0. 0. 6. 0. 3. 0. 0. 1.]]\n",
            "[[7 1 2 8 9 5 4 3 6]\n",
            " [6 3 5 1 2 4 8 9 7]\n",
            " [9 8 4 7 3 6 5 1 2]\n",
            " [5 2 6 9 7 1 3 4 8]\n",
            " [8 4 3 5 6 2 1 7 9]\n",
            " [1 7 9 3 4 8 6 2 5]\n",
            " [3 6 8 2 1 9 7 5 4]\n",
            " [2 5 1 4 8 7 9 6 3]\n",
            " [4 9 7 6 5 3 2 8 1]]\n",
            "[[7 1 2 8 9 5 4 3 6]\n",
            " [6 3 5 1 2 4 8 9 7]\n",
            " [9 8 4 7 3 6 5 1 2]\n",
            " [5 2 6 9 7 1 3 4 8]\n",
            " [8 4 3 5 6 2 1 7 9]\n",
            " [1 7 9 3 4 8 6 2 5]\n",
            " [3 6 8 2 1 9 7 5 4]\n",
            " [2 5 1 4 8 7 9 6 3]\n",
            " [4 9 7 6 5 3 2 8 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}